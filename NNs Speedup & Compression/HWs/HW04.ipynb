{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ISP-2022. NNSC. Quantization. Homework4(Chernyy Vladimir) .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Inroduction\n",
        "\n",
        "Useful links:\n",
        "- Intorduction to Quantization on PyTorch https://pytorch.org/blog/introduction-to-quantization-on-pytorch/\n",
        "- PyTorch modules that provide quantization classes and functions https://pytorch.org/docs/stable/quantization.html#modules-that-provide-quantization-functions-and-classes"
      ],
      "metadata": {
        "id": "7HUpO-yxyu4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install tensorly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ifoi_ZoB0N8C",
        "outputId": "ebbe40af-15ac-4f45-abcb-6561e389d601"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorly in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.7/dist-packages (from tensorly) (1.3.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorly) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from tensorly) (1.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "12DSg2szEb7t"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from collections import defaultdict\n",
        "import copy\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorly as tl\n",
        "tl.set_backend('pytorch')"
      ],
      "metadata": {
        "id": "RbvTEjfG2F07"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1 [2 points]\n",
        "\n",
        "For X = DD + MM + YY + YY, where DD/MM/YYYY is your date of birth  \n",
        "\n",
        "1. Represent the number X in the following formats:\n",
        "\n",
        "  a) int8,  big-endian\n",
        "\n",
        "  b) int8, little-endian\n",
        "\n",
        "  c) int16, big-endian\n",
        "\n",
        "  d) int16, little-endian\n",
        "\n",
        "  e) float32, big-endian\n",
        "\n",
        "  f) float32, little-endian\n",
        "\n",
        "2. Write representations in the same formats a)-e) for -X\n",
        "\n",
        "\n",
        "Use the following style when writing/printing:\n",
        "\n",
        "- For all cases: 8 bits - space - 8 bits - space - ...\n",
        "\n",
        "- Additionally, for float big-endian format print the result the following ways: \n",
        "\n",
        "  - sign bit - space - exponent bits - space - fraction bits\n",
        "\n",
        "  - sign multiplier - space - exponent multiplier - space - faction multiplier (all multipliers in float format, multiply them to check whether the result is close to the initial number)  \n",
        "\n"
      ],
      "metadata": {
        "id": "GV9vvuv0EjXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = 14 + 8 + 19 + 99\n",
        "x"
      ],
      "metadata": {
        "id": "EPm6Zkh66EK5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c12f1d1-4301-4551-e430-e21c86fb4055"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "140"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import struct"
      ],
      "metadata": {
        "id": "bgHEdqLhrLIP"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_binary(v, fmt = 'f', input_type = None, return_type = None):\n",
        "  if input_type != 'hex':\n",
        "    v_packed = struct.pack('{}'.format(fmt), v)\n",
        "    # print(v_packed)\n",
        "  else:\n",
        "    return v_packed\n",
        "\n",
        "  v_binaries = [bin(i) for i in v_packed]\n",
        "#   print(v_binaries)\n",
        "\n",
        "  v_binaries_stripped = [s.replace('0b', '') for s in v_binaries]\n",
        "  # print(v_binaries_stripped)\n",
        "\n",
        "  v_padded = [s.rjust(8, '0') for s in v_binaries_stripped]\n",
        "#   print(v_padded)\n",
        "\n",
        "  if fmt == '!f' and 'float' in v.__class__.__name__:\n",
        "    tmp = ''.join(v_padded)\n",
        "    a, b, c = tmp[0], tmp[1:9], tmp[9:]\n",
        "\n",
        "    return ' '.join([a, b, c])   \n",
        "\n",
        "  return ' '.join(v_padded)"
      ],
      "metadata": {
        "id": "HU76re39qOO4"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from math import pow, inf, nan\n",
        "\n",
        "def combine_str_realnumber_parts(sign: str, exponent: str, fraction: str):\n",
        "  \"\"\"\n",
        "  Input: sign, exponent and fraction are the parts of binary representation of \n",
        "  floating point number.\n",
        "  \"\"\"\n",
        "\n",
        "  s = ''.join([sign, exponent, fraction])\n",
        "  assert set(s) == set(['0', '1']), \"Strings should contain only '0' and '1'\"\n",
        "\n",
        "  sign = 1. if sign == '0' else -1.\n",
        "\n",
        "  if set(exponent) == set('1'):     # exponent is consist of only ones\n",
        "    if set(fraction) == set('0'):   # fraction is consist of only zeros\n",
        "      return sign * inf             # +- Infinity\n",
        "    else:\n",
        "      return nan                    # Not a Number\n",
        "\n",
        "  elif set(exponent) == set('0'):   # exponent is consist of only zeros\n",
        "    if set(fraction) == set('0'):   # fraction is consist of only zeros\n",
        "      return sign * 0               # +-0\n",
        "    else:\n",
        "      exp_multiplier = pow(2, 2 - (1<<len(exponent)-1))\n",
        "      frac_multiplier = int(fraction, 2) * 1. / (1<<len(fraction))\n",
        "      return sign * exp_multiplier * frac_multiplier    # Subnormal number (very small)\n",
        "  \n",
        "\n",
        "  exp_bias = 1 - (1<<(len(exponent)-1))\n",
        "  print(f\"2^(len(exponent)-1)-1 = {-exp_bias}\")\n",
        "  exp_multiplier_tmp = int(exponent, 2) + exp_bias\n",
        "  print(f\"2^(exponent{exp_bias}) = 2^{exp_multiplier_tmp}\")\n",
        "\n",
        "  exp_multiplier = pow(2, exp_multiplier_tmp)\n",
        "  frac_part = int(fraction, 2) * 1. / (1<<len(fraction))\n",
        "  print(f\"1.fraction = {1+frac_part}\")\n",
        "  frac_multiplier = 1. + frac_part\n",
        "  return sign * exp_multiplier * frac_multiplier  # Normal number (very small)\n",
        "  "
      ],
      "metadata": {
        "id": "1PeY-XPl_66X"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "gZv2JF00r-9r"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a) int8, big-endian**"
      ],
      "metadata": {
        "id": "4ZnamJp1r5yv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1."
      ],
      "metadata": {
        "id": "BIxYP-LxxXcE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_binary(np.int8(x), fmt='!f')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "LkkqgvgZr8tW",
        "outputId": "c2689ed2-149d-45e3-8186-c12194c12816"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'11000010 11101000 00000000 00000000'"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2."
      ],
      "metadata": {
        "id": "z3Pg_O0nBIif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_binary(np.int8(-x), fmt='!f')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "GQxuxEfdBKPY",
        "outputId": "662fa465-9aa2-4eb2-f959-0d35bb5b542d"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'01000010 11101000 00000000 00000000'"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b) int8, little-endian**"
      ],
      "metadata": {
        "id": "qCVvIeCtsFqt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1."
      ],
      "metadata": {
        "id": "wIll7QeyxcT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_binary(np.int8(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "_Yf5KPL_sL71",
        "outputId": "cb10579d-fd0d-431c-dfdb-227f39c3d6a4"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'00000000 00000000 11101000 11000010'"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2."
      ],
      "metadata": {
        "id": "SUxJmjHaBb4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_binary(np.int8(-x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "XtlUQY3cBaIN",
        "outputId": "956a53da-e78b-41a7-a976-c6b73aa23b1f"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'00000000 00000000 11101000 01000010'"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**c) int16, big-endian**"
      ],
      "metadata": {
        "id": "D8iNd8ZAwLEQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1."
      ],
      "metadata": {
        "id": "dwQkipgNxf9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_binary(np.int16(x), fmt='!f')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "B_hIMuaRsLvx",
        "outputId": "e66450e5-c8f6-4f09-b26d-4d5f7a74efbb"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'01000011 00001100 00000000 00000000'"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2."
      ],
      "metadata": {
        "id": "SRnywwijBnYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_binary(np.int16(-x), fmt='!f')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "crGcfiMSBmKA",
        "outputId": "aadc554c-9257-42c0-87d9-b15578aa80f9"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'11000011 00001100 00000000 00000000'"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**d) int16, little-endian**"
      ],
      "metadata": {
        "id": "jt3dwMcfwOcZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1."
      ],
      "metadata": {
        "id": "d4Tx65_uxhmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_binary(np.int16(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "1SOkWredsLfV",
        "outputId": "105d1d39-eb03-44a3-8567-9499ff4e312b"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'00000000 00000000 00001100 01000011'"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2."
      ],
      "metadata": {
        "id": "ic1F9WcLBp2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_binary(np.int16(-x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "0rwSeaO0BrOX",
        "outputId": "ca038965-b12a-43f7-8c30-b39c5c62eab6"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'00000000 00000000 00001100 11000011'"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**e) float32, big-endian**"
      ],
      "metadata": {
        "id": "l2GUxC1Qw4gr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1."
      ],
      "metadata": {
        "id": "b0Ql_wZmxksP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bin_v = get_binary(np.float32(x), fmt='!f')\n",
        "bin_v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "_vIp47yisLMz",
        "outputId": "56a94c07-1160-45d0-960f-78d5fde5ea88"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0 10000110 00011000000000000000000'"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combine_str_realnumber_parts(*bin_v.split(' '))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64iXBkjeAECw",
        "outputId": "e3c90509-1edb-4dc0-b339-a62dd30d3e03"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2^(len(exponent)-1)-1 = 127\n",
            "2^(exponent-127) = 2^7\n",
            "1.fraction = 1.09375\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "140.0"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2."
      ],
      "metadata": {
        "id": "wzzAwLKgB096"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bin_v = get_binary(np.float32(-x), fmt='!f')\n",
        "bin_v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "ng0MvSS2ByfK",
        "outputId": "d361a941-d2ee-414d-8bf3-e2a65400bcb5"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1 10000110 00011000000000000000000'"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combine_str_realnumber_parts(*bin_v.split(' '))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCDIlcjkB4fi",
        "outputId": "5db8a363-6368-46c8-cb55-01c85be08341"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2^(len(exponent)-1)-1 = 127\n",
            "2^(exponent-127) = 2^7\n",
            "1.fraction = 1.09375\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-140.0"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**f) float32, little-endian**"
      ],
      "metadata": {
        "id": "SNaXdBdVwnXn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1."
      ],
      "metadata": {
        "id": "_YgbQE4cxlt2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_binary(np.float32(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "G2-k8OlYy00N",
        "outputId": "428d2d32-888b-490b-f941-0cd11fe61bb4"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'00000000 00000000 00001100 01000011'"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2."
      ],
      "metadata": {
        "id": "556QXP5rwoSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_binary(np.float32(-x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "dA01oU3zB8_z",
        "outputId": "be479d46-12fa-4e91-d277-b04388b002f5"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'00000000 00000000 00001100 11000011'"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2 [4 point]\n",
        "\n",
        "Given tensor X and using PyTorch tools\n",
        "\n",
        "\n",
        "1. Implement per-tensor affine quantization :\n",
        "\n",
        "  a) int8 symmetric \n",
        "\n",
        "  b) uint8 symmetric \n",
        "\n",
        "  c) int8 assymmetric\n",
        "\n",
        "  You'll need to do that for several given input tensors.\n",
        "  \n",
        "  - What can you say by comparing approximation errors of a)-c) representations? \n",
        "\n",
        "  - Explain why some quantization schemes suit better for some inputs.\n",
        "\n",
        "2. Implement per-tensor and per-channel (along axis = 0) affine quantization using int8 symmetric quantization.\n",
        "\n",
        "  You'll need to do that for several given input tensors.\n",
        "\n",
        "  - What can you say  by comparing approximation errors for per-tensor and per-channel quantization  for different inputs? \n",
        "\n",
        "  - Explain why some quantization schemes suit better for some inputs.\n",
        "\n",
        "\n",
        "Useful links:\n",
        "\n",
        "- Quantized Tensors in PyTorch: https://pytorch.org/docs/stable/quantization.html#quantized-tensors\n"
      ],
      "metadata": {
        "id": "bXFPiIBnGLBE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Demostrative Example\n",
        "\n",
        "Pay attention to types of tensors when performing quantization / dequantization using PyTorch tools\n"
      ],
      "metadata": {
        "id": "kV5LHM_iVf4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a float tensor\n",
        "t = torch.arange(512).reshape(32, 16) + torch.randn((32, 16))\n",
        "\n",
        "print(f'After generation: \\n\\t type: {t.dtype}, \\n\\n\\t tesor: {t[0, :]}')\n",
        "\n",
        "# Quantize the tensor\n",
        "qt = torch.quantize_per_tensor(t, scale=1.5, zero_point=0, dtype=torch.qint8)\n",
        "\n",
        "print(f'\\n\\nAfter quantization: \\n\\t type: {qt.dtype},'+\n",
        "      f'\\n\\n\\t quantized tensor in float representation: {qt[0, :]},'+\n",
        "      f' \\n\\n\\t quantized tensor in int representation: {qt.int_repr()[0, :]}')\n",
        "\n",
        "# Dequantize the tensor\n",
        "dqt = qt.dequantize()\n",
        "\n",
        "print(f'\\n\\nAfter dequantization: \\n\\t type: {dqt.dtype}, \\n\\n\\t dequantized tesor: {dqt[0, :]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXZsWRG2gNZf",
        "outputId": "deecf552-c741-40a1-87bc-409819109446"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After generation: \n",
            "\t type: torch.float32, \n",
            "\n",
            "\t tesor: tensor([ 1.3892,  3.8885,  1.5940,  3.2478,  3.7736,  3.0347,  6.2459,  7.1071,\n",
            "         8.0800,  9.3021,  9.5425, 12.0443,  9.7773, 12.3405, 13.9883, 14.0674])\n",
            "\n",
            "\n",
            "After quantization: \n",
            "\t type: torch.qint8,\n",
            "\n",
            "\t quantized tensor in float representation: tensor([ 1.5000,  4.5000,  1.5000,  3.0000,  4.5000,  3.0000,  6.0000,  7.5000,\n",
            "         7.5000,  9.0000,  9.0000, 12.0000, 10.5000, 12.0000, 13.5000, 13.5000],\n",
            "       size=(16,), dtype=torch.qint8,\n",
            "       quantization_scheme=torch.per_tensor_affine, scale=1.5, zero_point=0), \n",
            "\n",
            "\t quantized tensor in int representation: tensor([1, 3, 1, 2, 3, 2, 4, 5, 5, 6, 6, 8, 7, 8, 9, 9], dtype=torch.int8)\n",
            "\n",
            "\n",
            "After dequantization: \n",
            "\t type: torch.float32, \n",
            "\n",
            "\t dequantized tesor: tensor([ 1.5000,  4.5000,  1.5000,  3.0000,  4.5000,  3.0000,  6.0000,  7.5000,\n",
            "         7.5000,  9.0000,  9.0000, 12.0000, 10.5000, 12.0000, 13.5000, 13.5000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print scale and zero_point\n",
        "try:\n",
        "  print(qt.q_scale(), qt.q_zero_point())\n",
        "except:\n",
        "  print(qt.q_per_channel_scales(), qt.q_zero_points())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrByZJteI9KO",
        "outputId": "58feac36-ccdf-429d-95f0-606badc80668"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.5 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2.0 Implement Quantization / Dequantization [2 point]"
      ],
      "metadata": {
        "id": "avpbPwedXQ7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def quantize_tensor(x, torch_dtype, is_symmetric=True, is_per_channel=False, axis = 0):\n",
        "  if is_per_channel:\n",
        "    x_quantized = quantize_tensor_per_channel(x, torch_dtype, is_symmetric, axis)\n",
        "\n",
        "  else:\n",
        "    x_quantized = quantize_tensor_per_tensor(x, torch_dtype, is_symmetric)\n",
        "\n",
        "  return x_quantized"
      ],
      "metadata": {
        "id": "bNt1LBVxRb54"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Per Tensor Quantization. Fill the blanks in the code."
      ],
      "metadata": {
        "id": "dewba8mXRg0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def quantize_tensor_per_tensor(x, torch_dtype, is_symmetric=True):\n",
        "\n",
        "    print(f\"\\nQuantization type: {torch_dtype}, symmetric: {is_symmetric}, per_channel: {False} \")\n",
        "\n",
        "    bits = torch.iinfo(torch_dtype).bits\n",
        "\n",
        "    # Minimum  and maximum quantization values\n",
        "    if torch_dtype == torch.qint8: # torch.iinfo(torch_dtype).min != 0 \n",
        "      quant_min = -2**(bits - 1) \n",
        "      quant_max = 2**(bits - 1) - 1\n",
        "\n",
        "    elif torch_dtype == torch.quint8: #\n",
        "      quant_min = 0 \n",
        "      quant_max = 2**bits - 1\n",
        "\n",
        "    x_min = x.min()\n",
        "    x_max = x.max()\n",
        "    \n",
        "\n",
        "    if is_symmetric:\n",
        "      scale = 2 * torch.where(x_min.abs() > x_max, x_min.abs(), x_max) / (quant_max - quant_min)\n",
        "      zero_point = 2**(bits - 1) if torch.iinfo(torch_dtype).min == 0 else 0\n",
        "    else:\n",
        "      x_max = max(x_max, 0)\n",
        "      x_min = min(x_min, 0)\n",
        "      \n",
        "      scale = (x_max - x_min) / (quant_max - quant_min)\n",
        "      zero_point = quant_min - torch.round(x_min / scale)\n",
        "\n",
        "\n",
        "    # Use PyTorch build-in function\n",
        "    x_quantized = torch.quantize_per_tensor(x, scale = scale, zero_point = zero_point, dtype = torch_dtype)\n",
        "\n",
        "    return x_quantized                                          \n"
      ],
      "metadata": {
        "id": "8sRxU_KvI79J"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unit test\n",
        "t = torch.ones(512).reshape(32, 16)\n",
        "qt = quantize_tensor_per_tensor(t, torch.qint8, is_symmetric=False)\n",
        "assert torch.max(t - qt.dequantize()) < torch.finfo(t.dtype).eps\n",
        "\n",
        "t = torch.ones(512).reshape(32, 16) + 1e-8\n",
        "qt = quantize_tensor_per_tensor(t, torch.qint8, is_symmetric=False)\n",
        "assert torch.max(t - qt.dequantize()) < torch.finfo(t.dtype).eps\n",
        "\n",
        "t = torch.arange(256).reshape(8, 32).to(torch.float32)\n",
        "qt = quantize_tensor_per_tensor(t, torch.qint8, is_symmetric=False)\n",
        "assert torch.max(t - qt.dequantize()) < torch.finfo(t.dtype).eps"
      ],
      "metadata": {
        "id": "soI5KQfbSxxj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2f9993e-6eb8-4b46-f84b-c8e038312940"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Quantization type: torch.qint8, symmetric: False, per_channel: False \n",
            "\n",
            "Quantization type: torch.qint8, symmetric: False, per_channel: False \n",
            "\n",
            "Quantization type: torch.qint8, symmetric: False, per_channel: False \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Per Channel Quantization. Fill the blanks in the code."
      ],
      "metadata": {
        "id": "whwFETilRGZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def quantize_tensor_per_channel(x, torch_dtype, is_symmetric=True, axis = 0):\n",
        "  '''\n",
        "  Takes float PyTorch tensor as input.\n",
        "  \n",
        "  Returns\n",
        "  -------\n",
        "  x_quantized: PyTorch tensor of PyTorch quantization types (e.g., torch.qint8, torch.quint8)\n",
        "    This format contains integer representation, scale, zero_point.\n",
        "    If you want to extract integer representation use 'x_int = x_quantized.int_repr()'.\n",
        "  '''\n",
        "  \n",
        "  print(f\"\\nQuantization type: {torch_dtype}, symmetric: {is_symmetric}, per_channel: {True} \")\n",
        "\n",
        "  bits = torch.iinfo(torch_dtype).bits\n",
        "\n",
        "\n",
        "  if torch_dtype==torch.qint8:\n",
        "    quant_min = -2**(bits - 1)\n",
        "    quant_max = 2**(bits - 1) - 1\n",
        "\n",
        "  elif torch_dtype==torch.quint8:\n",
        "    quant_min = 0\n",
        "    quant_max = 2**bits - 1\n",
        "\n",
        "\n",
        "  unfolded_t = tl.base.unfold(x, mode=axis)\n",
        "\n",
        "  x_max = unfolded_t.max(dim = -1)[0]\n",
        "  x_min = unfolded_t.min(dim = -1)[0]\n",
        "\n",
        "\n",
        "  if is_symmetric:\n",
        "    scale = 2 * torch.where(x_min.abs() > x_max, x_min.abs(), x_max) / (quant_max - quant_min) \n",
        "    \n",
        "    zero_point = torch.repeat_interleave(\n",
        "        torch.tensor(2**(bits - 1) if torch.iinfo(torch_dtype).min == 0 else 0),\n",
        "        len(scale))\n",
        "\n",
        "  else:\n",
        "    x_max = torch.where(x_max < torch.zeros_like(x_max), torch.zeros_like(x_max), x_max)\n",
        "    x_min = torch.where(x_min > torch.zeros_like(x_min), torch.zeros_like(x_min), x_min)\n",
        "\n",
        "    scale = (x_max - x_min) / (quant_max - quant_min)\n",
        "    zero_point = quant_min - torch.round(x_min / scale)\n",
        "\n",
        "    \n",
        "\n",
        "  # Use PyTorch build-in function \n",
        "  x_quantized = torch.quantize_per_channel(x, scales = scale,\n",
        "                                              zero_points = zero_point,\n",
        "                                              dtype = torch_dtype,\n",
        "                                              axis = axis)\n",
        "  return x_quantized"
      ],
      "metadata": {
        "id": "L7Dx-q68RNWh"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unit test\n",
        "t = torch.ones(512).reshape(32, 16).to(torch.float32)\n",
        "qt = quantize_tensor_per_channel(t, torch.qint8, is_symmetric=False)\n",
        "assert torch.max(t - qt.dequantize()) < torch.finfo(t.dtype).eps\n",
        "\n",
        "t = torch.ones(512).reshape(32, 16) + 1e-2\n",
        "qt = quantize_tensor_per_channel(t, torch.qint8, is_symmetric=False)\n",
        "assert torch.max(t - qt.dequantize()) < torch.finfo(t.dtype).eps\n",
        "\n",
        "t = torch.arange(256).reshape(1, 256).to(torch.float32)\n",
        "qt = quantize_tensor_per_channel(t, torch.qint8, is_symmetric=False)\n",
        "assert torch.max(t - qt.dequantize()) < torch.finfo(t.dtype).eps"
      ],
      "metadata": {
        "id": "Yp0JxKL3S0j0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a623689-d1da-4e1c-db5a-4c2e773571c8"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Quantization type: torch.qint8, symmetric: False, per_channel: True \n",
            "\n",
            "Quantization type: torch.qint8, symmetric: False, per_channel: True \n",
            "\n",
            "Quantization type: torch.qint8, symmetric: False, per_channel: True \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor Dequantization. Fill blanks in the code. [1 point]"
      ],
      "metadata": {
        "id": "BpCwV6UpSHcg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dequantize_tensor(x_quantized):\n",
        "  # Implement using scale, zero_point, integer representation\n",
        "  if x_quantized.qscheme() == torch.per_tensor_affine:\n",
        "    \n",
        "    # Get scale, zero_point from x_quantized \n",
        "    \n",
        "    scale = x_quantized.q_scale()\n",
        "    zero_point = x_quantized.q_zero_point()\n",
        "\n",
        "  else:\n",
        "    axis = x_quantized.q_per_channel_axis() \n",
        "    \n",
        "    scale = x_quantized.q_per_channel_scales()\n",
        "    zero_point = x_quantized.q_per_channel_zero_points()\n",
        "\n",
        "    ## Broadcasting along axis:\n",
        "    for i, shp in enumerate(x_quantized.shape):\n",
        "      if i != axis:\n",
        "        scale.unsqueeze_(i)\n",
        "        zero_point.unsqueeze_(i)\n",
        "\n",
        "  x_int = x_quantized.int_repr().long()\n",
        "  x_dequantized = (x_int - zero_point) * scale\n",
        "  \n",
        "  return x_dequantized"
      ],
      "metadata": {
        "id": "Q-AsuK9hNyKp"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unit test\n",
        "t = torch.arange(512).reshape(32, 16) + torch.randn((32, 16))\n",
        "\n",
        "# Unit test1 \n",
        "qt = torch.quantize_per_tensor(t, scale=1.5, zero_point=0, dtype=torch.qint8)\n",
        "dqt = qt.dequantize()\n",
        "\n",
        "dqt_custom = dequantize_tensor(qt)\n",
        "\n",
        "rel_err = torch.norm(dqt - dqt_custom) / torch.norm(dqt)\n",
        "assert rel_err < torch.finfo(t.dtype).eps, rel_err\n",
        "\n",
        "\n",
        "# Unit test2\n",
        "qt = torch.quantize_per_channel(t, scales=torch.arange(16).to(torch.float), zero_points=torch.zeros(16, dtype=torch.int), dtype=torch.qint8, axis=1)\n",
        "dqt = qt.dequantize()\n",
        "\n",
        "dqt_custom = dequantize_tensor(qt)\n",
        "\n",
        "rel_err = torch.norm(dqt - dqt_custom) / torch.norm(dqt)\n",
        "assert rel_err < torch.finfo(t.dtype).eps, rel_err"
      ],
      "metadata": {
        "id": "Art3N4oVS3yH"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2.1. Perform Quantization. Analyze. [1 point]\n",
        "\n",
        "For three given tensors perform per-tensor affine quantization :\n",
        "a) int8 symmetric\n",
        "b) uint8 symmetric\n",
        "c) int8 assymmetric\n",
        "\n",
        "\n",
        "- What can you say by comparing approximation errors of a)-c) representations?\n",
        "- Explain why some quantization schemes suit better for some inputs."
      ],
      "metadata": {
        "id": "68U3tHjwpoY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shape = (512, 3, 3)\n",
        "x1 = torch.rand(shape) * 100     # uniform in the range [0, 100] \n",
        "x2 = torch.rand(shape) * 100 - 50 # uniform in the range [-50, 50] \n",
        "x3 = torch.rand(shape) * 100 - 20 # uniform in the range [-20, 80] \n",
        "\n",
        "\n",
        "results = defaultdict(dict)\n",
        "\n",
        "\n",
        "# Experiments 1\n",
        "for torch_dtype, is_symmetric, is_per_channel in [[torch.qint8, True, False],\n",
        "                                                  [torch.quint8, True, False],\n",
        "                                                  [torch.qint8, False, False]]:\n",
        "\n",
        "  tmp_dict = defaultdict()\n",
        "\n",
        "  for i, x in enumerate([x1, x2, x3]):\n",
        "    x_quantized = quantize_tensor(x,\n",
        "                                  torch_dtype = torch_dtype,\n",
        "                                  is_symmetric = is_symmetric,\n",
        "                                  is_per_channel = is_per_channel)\n",
        "    \n",
        "    approx_error = torch.norm(x_quantized.dequantize() - x)/torch.norm(x)\n",
        "\n",
        "    tmp_dict[i] = (x_quantized, approx_error)\n",
        "\n",
        "  key = (torch_dtype,\n",
        "         'symmetric' if is_symmetric else 'asymmetric',\n",
        "         'per_channel' if is_per_channel else 'per_tensor')\n",
        "  results[key] = tmp_dict\n",
        "  \n",
        "\n",
        "# Compute difference in approximations\n",
        "for i, x in enumerate([x1, x2, x3]):\n",
        "  print(f\"\\ntensor number {i}, tensor range: {(x.min(), x.max())}\")\n",
        "  for key in results.keys():\n",
        "    print(f'\\tquantization scheme {key}, approx_error: {results[key][i][1]}')\n",
        "\n"
      ],
      "metadata": {
        "id": "QgET8GaHEoNR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6a4e082-cf4a-4285-d29a-b733771f9705"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Quantization type: torch.qint8, symmetric: True, per_channel: False \n",
            "\n",
            "Quantization type: torch.qint8, symmetric: True, per_channel: False \n",
            "\n",
            "Quantization type: torch.qint8, symmetric: True, per_channel: False \n",
            "\n",
            "Quantization type: torch.quint8, symmetric: True, per_channel: False \n",
            "\n",
            "Quantization type: torch.quint8, symmetric: True, per_channel: False \n",
            "\n",
            "Quantization type: torch.quint8, symmetric: True, per_channel: False \n",
            "\n",
            "Quantization type: torch.qint8, symmetric: False, per_channel: False \n",
            "\n",
            "Quantization type: torch.qint8, symmetric: False, per_channel: False \n",
            "\n",
            "Quantization type: torch.qint8, symmetric: False, per_channel: False \n",
            "\n",
            "tensor number 0, tensor range: (tensor(0.0006), tensor(99.9032))\n",
            "\tquantization scheme (torch.qint8, 'symmetric', 'per_tensor'), approx_error: 0.003883491037413478\n",
            "\tquantization scheme (torch.quint8, 'symmetric', 'per_tensor'), approx_error: 0.003883491037413478\n",
            "\tquantization scheme (torch.qint8, 'asymmetric', 'per_tensor'), approx_error: 0.0019364061299711466\n",
            "\n",
            "tensor number 1, tensor range: (tensor(-49.9905), tensor(49.9757))\n",
            "\tquantization scheme (torch.qint8, 'symmetric', 'per_tensor'), approx_error: 0.003921571187674999\n",
            "\tquantization scheme (torch.quint8, 'symmetric', 'per_tensor'), approx_error: 0.003921571187674999\n",
            "\tquantization scheme (torch.qint8, 'asymmetric', 'per_tensor'), approx_error: 0.003921798896044493\n",
            "\n",
            "tensor number 2, tensor range: (tensor(-19.9896), tensor(79.9955))\n",
            "\tquantization scheme (torch.qint8, 'symmetric', 'per_tensor'), approx_error: 0.004431181587278843\n",
            "\tquantization scheme (torch.quint8, 'symmetric', 'per_tensor'), approx_error: 0.004431181587278843\n",
            "\tquantization scheme (torch.qint8, 'asymmetric', 'per_tensor'), approx_error: 0.0027297150809317827\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analysis**:\n",
        "\n",
        "1. for all a)-c) schemes â€“ non-negative range [0, 100] gives best relative performance\n",
        "\n",
        "2. for any range `int8 assymmetric` scheme performs best amongst all a)-c)\n",
        "\n",
        "3. the lack of zero-point offset restricts the mapping between integer and floating-point domain. Unsigned symmetric quantization is well suited for one-tailed distributions. On the other hand, signed symmetric quantization can be chosen for distributions that are roughly symmetric about zero.\n",
        "I got different result, but i think assymetric performs better here because its more flexible and can \"fit in\" range. "
      ],
      "metadata": {
        "id": "YMVLJSh195cW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2.2. Perform Quantization. Analyze. [1 point]\n",
        "\n",
        "For two given tensors perform per-tensor and per-channel (along axis = 0) affine quantization using int8 symmetric quantization.\n",
        "\n",
        "- What can you say by comparing approximation errors for per-tensor and per-channel quantization for different inputs?\n",
        "- Explain why some quantization schemes suit better for some inputs."
      ],
      "metadata": {
        "id": "-G97qbqZptRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shape = (1024, 32, 64)\n",
        "x1 = torch.rand(shape) * 100    # uniform in the range [0, 100] \n",
        "x1 = x1 * torch.arange(1, 1 + shape[0])[:, None, None] # then multiple each channel by (channel_index + 1)\n",
        "\n",
        "x2 = torch.rand(shape) * 100 - 50 # uniform in the range [-50, 50] \n",
        "\n",
        "results = defaultdict(dict)\n",
        "\n",
        "\n",
        "# Experiments 2\n",
        "for torch_dtype, is_symmetric, is_per_channel in [[torch.qint8, True, False],\n",
        "                                                  [torch.qint8, True, True]]:\n",
        "\n",
        "  tmp_dict = defaultdict()\n",
        "\n",
        "  for i, x in enumerate([x1, x2]):\n",
        "    x_quantized = quantize_tensor(x,\n",
        "                                  torch_dtype = torch_dtype,\n",
        "                                  is_symmetric = is_symmetric,\n",
        "                                  is_per_channel = is_per_channel,\n",
        "                                  axis = 0)\n",
        "    \n",
        "    approx_error = torch.norm(x_quantized.dequantize() - x)/torch.norm(x)\n",
        "\n",
        "    tmp_dict[i] = (x_quantized, approx_error)\n",
        "\n",
        "  key = (torch_dtype,\n",
        "         'symmetric' if is_symmetric else 'asymmetric',\n",
        "         'per_channel' if is_per_channel else 'per_tensor')\n",
        "  results[key] = tmp_dict\n",
        "  \n",
        "\n",
        "# Compute difference in approximations\n",
        "for i, x in enumerate([x1, x2]):\n",
        "  print(f\"\\ntensor number {i}, tensor range: {(x.min(), x.max())}\")\n",
        "  for key in results.keys():\n",
        "    print(f'\\tquantization scheme {key}, approx_error: {results[key][i][1]}')\n"
      ],
      "metadata": {
        "id": "mxHCAvvep3ZI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "569c8869-9f78-4fe8-a668-1baa55ef50bc"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Quantization type: torch.qint8, symmetric: True, per_channel: False \n",
            "\n",
            "Quantization type: torch.qint8, symmetric: True, per_channel: False \n",
            "\n",
            "Quantization type: torch.qint8, symmetric: True, per_channel: True \n",
            "\n",
            "Quantization type: torch.qint8, symmetric: True, per_channel: True \n",
            "\n",
            "tensor number 0, tensor range: (tensor(0.0029), tensor(102246.3750))\n",
            "\tquantization scheme (torch.qint8, 'symmetric', 'per_tensor'), approx_error: 0.006762108765542507\n",
            "\tquantization scheme (torch.qint8, 'symmetric', 'per_channel'), approx_error: 0.003917887341231108\n",
            "\n",
            "tensor number 1, tensor range: (tensor(-50.0000), tensor(50.0000))\n",
            "\tquantization scheme (torch.qint8, 'symmetric', 'per_tensor'), approx_error: 0.003925025463104248\n",
            "\tquantization scheme (torch.qint8, 'symmetric', 'per_channel'), approx_error: 0.003924800548702478\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "X3sob1RFWa5t"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDFyH0rIYZn9",
        "outputId": "90a0572d-1e35-461c-b026-275a3a52216c"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 7))\n",
        "\n",
        "data = [x1[i].reshape(-1).numpy() for i in range(50)]\n",
        "\n",
        "plt.boxplot(data)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "oMx4YNSTWefX",
        "outputId": "c8b60714-06c3-4389-9034-21c2ae33a8e8"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analysis**:\n",
        "\n",
        "1. `per_channel` scheme performs better for any range\n",
        "\n",
        "2. scheme to best-suitable range:\n",
        "\n",
        "    a) `per_channel` â€“ [-50, 50]\n",
        "\n",
        "    b) `per_tensor` â€“ [-50, 50]\n",
        "\n",
        "3. `per-channel` quantization of the weights can improve accuracy, especially when the distribution of weights varies significantly from channel to channel, like we can see on the plot above. IMHO it is connected with the fact, that its easier to transform narrow float sub-range, that the whole tensor's range."
      ],
      "metadata": {
        "id": "-3srDlZZ96ab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 3 [4 points]\n",
        "\n",
        "Consider a simple PyTorch model and modify it using QuantStub() and DeQuantStub() to imitate\n",
        "\n",
        "1) Quantization of all layers\n",
        "\n",
        "2) Quantization only of convolutionsl layers\n",
        "\n",
        "Useful links:\n",
        "- PyTorch model preparation for Quantization https://pytorch.org/docs/stable/quantization.html#model-preparation-for-quantization\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cmYn96M0K4Yp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Important PyTorch build-in modules/methods/attributes for Quantization\n",
        "\n",
        "Below we provide some details on PyTorch build-in tools you need to set the quantization configuration, prepare the model and quantize it.\n",
        "\n"
      ],
      "metadata": {
        "id": "AcMQ3sV6dun_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### QuantStub() and DeQuantStub()\n",
        "\n",
        "`QuantStub(qconfig)` and `DeQuantStub()` are modules that are swapped to `nnq.Quantize()` and `nnq.DeQuantize()` in `convert()` and perform quantization of activations according to the qconfig.\n",
        "\n",
        "- `QuantStub, DequantStub` https://github.com/pytorch/pytorch/blob/d5a757959730b5889a5acfe20fb6a932fb58c157/torch/quantization/stubs.py#L4\n",
        "\n",
        "- `nnq.Quantize, nnq.Dequantize` https://github.com/pytorch/pytorch/blob/4f390eb6b681fa658614789c5c8992c23d40d03b/torch/nn/quantized/modules/__init__.py\n",
        "\n",
        "If `qconfig = None` nothing happens: output of `QuantStub()` has `float32` format.\n",
        "\n",
        "If `qconfig.activation.p.keywords['dtype'] == torch.quint8`, then `QuantStub()` peforms quantization of  activations according to the quantization scheme described using `qconfig.activation.p.keywords`."
      ],
      "metadata": {
        "id": "_SLpdMHKzkn9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### prepare()\n",
        "https://github.com/pytorch/pytorch/blob/9cc44aad21110e7dd481d4d1979c1569059144c2/torch/ao/quantization/quantize.py#L204\n",
        "\n",
        "Prepares a copy of the model for quantization calibration or quantization-aware training.\n",
        "\n",
        "Quantization configuration should be assigned preemptively\n",
        " to individual submodules in `.qconfig` attribute.\n",
        "\n",
        "The model will be attached with observer or fake quant modules, and qconfig\n",
        " will be propagated.\n",
        "\n",
        "- get_default_propagation_list() https://github.com/pytorch/pytorch/blob/9cc44aad21110e7dd481d4d1979c1569059144c2/torch/quantization/quantization_mappings.py#L189 Get the default list of module types that we'll attach qconfig\n",
        "    attribute to in prepare\n"
      ],
      "metadata": {
        "id": "rBbstxqLeWZ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### convert()\n",
        "https://github.com/pytorch/pytorch/blob/9cc44aad21110e7dd481d4d1979c1569059144c2/torch/ao/quantization/quantize.py#L446\n",
        "\n",
        "Converts submodules in the input module to a different module according to `mapping`\n",
        "    by calling `from_float` method on the target module class"
      ],
      "metadata": {
        "id": "vsVZnGKie13z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyTorch module used for the layer implementation depends on the weights' type and on the computations' type during the propagation. \n",
        "\n",
        "\n",
        "**Conv2d**  can be represented using different PyTorch modules:\n",
        "- nn.Conv2d - float weights \n",
        "- nnq.Conv2d - quantized weights, int8 computations (when convolved with uint8 input)\n",
        "- nnqat.Conv2d - quantized weights, float32 computations (when convolved with uint8 input) => used for QAT training via Fake Quantization"
      ],
      "metadata": {
        "id": "dSELSU9ZgNaB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Module mappings during Quantization\n",
        "\n",
        "https://github.com/pytorch/pytorch/blob/9cc44aad21110e7dd481d4d1979c1569059144c2/torch/quantization/quantization_mappings.py\n",
        "\n",
        "When perform quantization, we convert modules that work with float format to modules that work with lower precision format.\n",
        "\n",
        "Let us see where float modules are mapped during Post Training Quantization by printing PyTorch built-in config. \n",
        "\n",
        "Note, that both\n",
        "- Convolutional layer `torch.nn.modules.conv.Conv2d` \n",
        "- Convolutional layer fused with Batch Normalization layer `torch.nn.intrinsic.qat.modules.conv_fused.ConvBn2d`\n",
        "\n",
        "are converted to `torch.nn.quantized.modules.conv.Conv2d` "
      ],
      "metadata": {
        "id": "7DZj-uesgyq0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Demonstrative Example"
      ],
      "metadata": {
        "id": "LNEbvhVx0GUl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Default module mappings "
      ],
      "metadata": {
        "id": "Z10tVAuZ0UUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.quantization.quantization_mappings import DEFAULT_STATIC_QUANT_MODULE_MAPPINGS\n",
        "\n",
        "# Mappings for Post Training quantization \n",
        "# (note that during Quantization Aware Training other quantized modules are used)\n",
        "DEFAULT_STATIC_QUANT_MODULE_MAPPINGS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1tzPFUWgvE7",
        "outputId": "9be8e435-9957-427a-89a7-ddc0bd80577a"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{torch.ao.quantization.stubs.DeQuantStub: torch.nn.quantized.modules.DeQuantize,\n",
              " torch.ao.quantization.stubs.QuantStub: torch.nn.quantized.modules.Quantize,\n",
              " torch.nn.intrinsic.modules.fused.BNReLU2d: torch.nn.intrinsic.quantized.modules.bn_relu.BNReLU2d,\n",
              " torch.nn.intrinsic.modules.fused.BNReLU3d: torch.nn.intrinsic.quantized.modules.bn_relu.BNReLU3d,\n",
              " torch.nn.intrinsic.modules.fused.ConvReLU1d: torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU1d,\n",
              " torch.nn.intrinsic.modules.fused.ConvReLU2d: torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d,\n",
              " torch.nn.intrinsic.modules.fused.ConvReLU3d: torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU3d,\n",
              " torch.nn.intrinsic.modules.fused.LinearReLU: torch.nn.intrinsic.quantized.modules.linear_relu.LinearReLU,\n",
              " torch.nn.intrinsic.qat.modules.conv_fused.ConvBn1d: torch.nn.quantized.modules.conv.Conv1d,\n",
              " torch.nn.intrinsic.qat.modules.conv_fused.ConvBn2d: torch.nn.quantized.modules.conv.Conv2d,\n",
              " torch.nn.intrinsic.qat.modules.conv_fused.ConvBn3d: torch.nn.quantized.modules.conv.Conv3d,\n",
              " torch.nn.intrinsic.qat.modules.conv_fused.ConvBnReLU1d: torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU1d,\n",
              " torch.nn.intrinsic.qat.modules.conv_fused.ConvBnReLU2d: torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d,\n",
              " torch.nn.intrinsic.qat.modules.conv_fused.ConvBnReLU3d: torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU3d,\n",
              " torch.nn.intrinsic.qat.modules.conv_fused.ConvReLU2d: torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d,\n",
              " torch.nn.intrinsic.qat.modules.conv_fused.ConvReLU3d: torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU3d,\n",
              " torch.nn.intrinsic.qat.modules.linear_relu.LinearReLU: torch.nn.intrinsic.quantized.modules.linear_relu.LinearReLU,\n",
              " torch.nn.modules.activation.ELU: torch.nn.quantized.modules.activation.ELU,\n",
              " torch.nn.modules.activation.Hardswish: torch.nn.quantized.modules.activation.Hardswish,\n",
              " torch.nn.modules.activation.LeakyReLU: torch.nn.quantized.modules.activation.LeakyReLU,\n",
              " torch.nn.modules.activation.ReLU6: torch.nn.quantized.modules.activation.ReLU6,\n",
              " torch.nn.modules.batchnorm.BatchNorm2d: torch.nn.quantized.modules.batchnorm.BatchNorm2d,\n",
              " torch.nn.modules.batchnorm.BatchNorm3d: torch.nn.quantized.modules.batchnorm.BatchNorm3d,\n",
              " torch.nn.modules.conv.Conv1d: torch.nn.quantized.modules.conv.Conv1d,\n",
              " torch.nn.modules.conv.Conv2d: torch.nn.quantized.modules.conv.Conv2d,\n",
              " torch.nn.modules.conv.Conv3d: torch.nn.quantized.modules.conv.Conv3d,\n",
              " torch.nn.modules.conv.ConvTranspose1d: torch.nn.quantized.modules.conv.ConvTranspose1d,\n",
              " torch.nn.modules.conv.ConvTranspose2d: torch.nn.quantized.modules.conv.ConvTranspose2d,\n",
              " torch.nn.modules.instancenorm.InstanceNorm1d: torch.nn.quantized.modules.normalization.InstanceNorm1d,\n",
              " torch.nn.modules.instancenorm.InstanceNorm2d: torch.nn.quantized.modules.normalization.InstanceNorm2d,\n",
              " torch.nn.modules.instancenorm.InstanceNorm3d: torch.nn.quantized.modules.normalization.InstanceNorm3d,\n",
              " torch.nn.modules.linear.Linear: torch.nn.quantized.modules.linear.Linear,\n",
              " torch.nn.modules.linear.NonDynamicallyQuantizableLinear: torch.nn.quantized.modules.linear.Linear,\n",
              " torch.nn.modules.normalization.GroupNorm: torch.nn.quantized.modules.normalization.GroupNorm,\n",
              " torch.nn.modules.normalization.LayerNorm: torch.nn.quantized.modules.normalization.LayerNorm,\n",
              " torch.nn.modules.sparse.Embedding: torch.nn.quantized.modules.embedding_ops.Embedding,\n",
              " torch.nn.modules.sparse.EmbeddingBag: torch.nn.quantized.modules.embedding_ops.EmbeddingBag,\n",
              " torch.nn.qat.modules.conv.Conv2d: torch.nn.quantized.modules.conv.Conv2d,\n",
              " torch.nn.qat.modules.conv.Conv3d: torch.nn.quantized.modules.conv.Conv3d,\n",
              " torch.nn.qat.modules.linear.Linear: torch.nn.quantized.modules.linear.Linear,\n",
              " torch.nn.quantized.modules.functional_modules.FloatFunctional: torch.nn.quantized.modules.functional_modules.QFunctional}"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Model\n"
      ],
      "metadata": {
        "id": "M5rrzsurk6MZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assume we have the following PyTorch model."
      ],
      "metadata": {
        "id": "ezsXkKFj1pu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume we have the following PyTorch model\n",
        "\n",
        "class MyM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.prev_conv = nn.Conv2d(3, 16, 5, 5)\n",
        "        self.conv = nn.Conv2d(16, 32, 3, 3)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.prev_conv(x)\n",
        "        x = self.conv(x)\n",
        "        \n",
        "        return x"
      ],
      "metadata": {
        "id": "EQRW8jfILgZd"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us prepare our model for Quantization https://pytorch.org/docs/stable/quantization.html#model-preparation-for-quantization\n",
        "\n",
        "We need to wrap modules we will quantize:\n",
        "- to collect statistics for activations  during calibration step and \n",
        "- to perform quantization of activations according to the `qconfig`.\n",
        "\n",
        "We can do that using \n",
        "- either `QuantStub(qconfig)` and `DeQuantStub()`\n",
        "- or `QuantWrapper`. This case is more convenient, because you don't need to modify `forward()` methods, you can just replace the nn.Module you quantize. \n"
      ],
      "metadata": {
        "id": "4p4bIVLComoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.quantization import QuantStub, DeQuantStub, QuantWrapper\n",
        "\n",
        "\n",
        "class MyMQ1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.prev_conv = nn.Conv2d(3, 16, 5, 5)\n",
        "\n",
        "        self.quant = QuantStub()\n",
        "        self.conv = nn.Conv2d(16, 32, 3, 3)\n",
        "        self.dequant = DeQuantStub()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.prev_conv(x)\n",
        "\n",
        "        x = self.quant(x)\n",
        "        x = self.conv(x)\n",
        "        x = self.dequant(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "class MyMQ2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.prev_conv = nn.Conv2d(3, 16, 5, 5)\n",
        "        self.conv = QuantWrapper(nn.Conv2d(16, 32, 3, 3))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.prev_conv(x)\n",
        "        x = self.conv(x)\n",
        "        \n",
        "        return x"
      ],
      "metadata": {
        "id": "H8O5UeWk5dv4"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyMQ1()\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9lb-mjL_HFm",
        "outputId": "d93afdba-39b3-4927-ff41-4e83d6aa8c8c"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyMQ1(\n",
              "  (prev_conv): Conv2d(3, 16, kernel_size=(5, 5), stride=(5, 5))\n",
              "  (quant): QuantStub()\n",
              "  (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(3, 3))\n",
              "  (dequant): DeQuantStub()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyMQ2()\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcGuPeah8XiN",
        "outputId": "9020d771-cc23-4ca7-f957-c6f8d4734b3c"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyMQ2(\n",
              "  (prev_conv): Conv2d(3, 16, kernel_size=(5, 5), stride=(5, 5))\n",
              "  (conv): QuantWrapper(\n",
              "    (quant): QuantStub()\n",
              "    (dequant): DeQuantStub()\n",
              "    (module): Conv2d(16, 32, kernel_size=(3, 3), stride=(3, 3))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyM()\n",
        "model.conv = QuantWrapper(model.conv)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcxNG50H-52g",
        "outputId": "125ae44c-4153-4075-ec19-1113f5123bce"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyM(\n",
              "  (prev_conv): Conv2d(3, 16, kernel_size=(5, 5), stride=(5, 5))\n",
              "  (conv): QuantWrapper(\n",
              "    (quant): QuantStub()\n",
              "    (dequant): DeQuantStub()\n",
              "    (module): Conv2d(16, 32, kernel_size=(3, 3), stride=(3, 3))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### QConfig\n"
      ],
      "metadata": {
        "id": "OvtsywI00kcx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to define how to quantize each nn.Module in our model by initializing its `qconfig`  attribute.\n",
        "\n",
        "If our module doesn't have `qconfig` attribute, we need to create it.\n",
        "\n",
        "If `module.qconfig = None` nothing happens during quantization.\n"
      ],
      "metadata": {
        "id": "1H1vz1rC1sxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_qconfig(model):\n",
        "  for mname, m in model.named_modules():\n",
        "    print(mname, ': does not have \"qconfig\" attribute'  if not hasattr(m, 'qconfig') else m.qconfig)"
      ],
      "metadata": {
        "id": "AC5ot8OlDqQj"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initially modules in our model don't have attribute `qconfig`\n",
        "check_qconfig(model)\n",
        "\n",
        "# Let define `qconfig=None` for all modules in the model\n",
        "model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
        "\n",
        "print('\\n---\\nAfter setting model.qconfig\\n---\\n')\n",
        "check_qconfig(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkZe5svYrwSm",
        "outputId": "d10a2391-0273-42bf-c97e-0f47917ca796"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " : does not have \"qconfig\" attribute\n",
            "prev_conv : does not have \"qconfig\" attribute\n",
            "conv : does not have \"qconfig\" attribute\n",
            "conv.quant : does not have \"qconfig\" attribute\n",
            "conv.dequant : does not have \"qconfig\" attribute\n",
            "conv.module : does not have \"qconfig\" attribute\n",
            "\n",
            "---\n",
            "After setting model.qconfig\n",
            "---\n",
            "\n",
            " QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})\n",
            "prev_conv : does not have \"qconfig\" attribute\n",
            "conv : does not have \"qconfig\" attribute\n",
            "conv.quant : does not have \"qconfig\" attribute\n",
            "conv.dequant : does not have \"qconfig\" attribute\n",
            "conv.module : does not have \"qconfig\" attribute\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we run `torch.quantization.prepare(model)`\n",
        "`qconfig` attribute of a child module is set to the `qconfig` value of its parent module')\n"
      ],
      "metadata": {
        "id": "YfW34xQDxLtQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.quantization.prepare(model, inplace=True)\n",
        "\n",
        "print('\\n---\\nAfter preparation. `qconfig` attribute is attached to all childrens\\n---\\n')\n",
        "check_qconfig(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNApEzkrxK2E",
        "outputId": "0a2a7862-939d-4353-cd8b-75c9c1144b04"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---\n",
            "After preparation. `qconfig` attribute is attached to all childrens\n",
            "---\n",
            "\n",
            " QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f9cb9cb98c0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f9cb9cb98c0>})\n",
            "prev_conv QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f9cba11b200>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f9cba11b200>})\n",
            "prev_conv.activation_post_process : does not have \"qconfig\" attribute\n",
            "conv QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f9cba11b0e0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f9cba11b0e0>})\n",
            "conv.quant QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f9cb9cb9830>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f9cb9cb9830>})\n",
            "conv.quant.activation_post_process : does not have \"qconfig\" attribute\n",
            "conv.dequant QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f9cba115320>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f9cba115320>})\n",
            "conv.module QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f9cb9cb93b0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f9cb9cb93b0>})\n",
            "conv.module.activation_post_process : does not have \"qconfig\" attribute\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/ao/quantization/observer.py:174: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  reduce_range will be deprecated in a future release of PyTorch.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Collecting statistics for Activations Quantization\n",
        "\n",
        "You should not forget to do this step to get right scale and zero_point dueing quantization!!!"
      ],
      "metadata": {
        "id": "H6XatJM6MagX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(20):\n",
        "  dummy_input = torch.randn(2, 3, 32, 32)\n",
        "  _ = model(dummy_input)  \n",
        "\n",
        "check_qconfig(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GeM7Nqxk2Uf",
        "outputId": "4ad6ca05-d88e-40e7-9cd8-d48f37b02b0d"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f9cb9cb98c0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f9cb9cb98c0>})\n",
            "prev_conv QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f9cba11b200>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f9cba11b200>})\n",
            "prev_conv.activation_post_process : does not have \"qconfig\" attribute\n",
            "conv QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f9cba11b0e0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f9cba11b0e0>})\n",
            "conv.quant QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f9cb9cb9830>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f9cb9cb9830>})\n",
            "conv.quant.activation_post_process : does not have \"qconfig\" attribute\n",
            "conv.dequant QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f9cba115320>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f9cba115320>})\n",
            "conv.module QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f9cb9cb93b0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x7f9cb9cb93b0>})\n",
            "conv.module.activation_post_process : does not have \"qconfig\" attribute\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, let quantize the model"
      ],
      "metadata": {
        "id": "aXmRE5q8rvnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.quantization.convert(model, inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nElqbG551iFp",
        "outputId": "8e904ada-81fa-49de-951d-a6aa7fa0d91c"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/ao/quantization/observer.py:886: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  src_bin_begin // dst_bin_width, 0, self.dst_nbins - 1\n",
            "/usr/local/lib/python3.7/dist-packages/torch/ao/quantization/observer.py:891: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  src_bin_end // dst_bin_width, 0, self.dst_nbins - 1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyM(\n",
              "  (prev_conv): QuantizedConv2d(3, 16, kernel_size=(5, 5), stride=(5, 5), scale=0.04000481218099594, zero_point=59)\n",
              "  (conv): QuantWrapper(\n",
              "    (quant): Quantize(scale=tensor([0.0400]), zero_point=tensor([59]), dtype=torch.quint8)\n",
              "    (dequant): DeQuantize()\n",
              "    (module): QuantizedConv2d(16, 32, kernel_size=(3, 3), stride=(3, 3), scale=0.0188146885484457, zero_point=64)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Your Task\n",
        "\n",
        "Given a class for a neural network prepare it to be quantizable and quantize.\n",
        "\n",
        "Namely, you should quantize\n",
        "\n",
        "1. whole model using default PyTorch static quantization qconfig\n",
        "\n",
        "2. part of the model\n"
      ],
      "metadata": {
        "id": "EuTXfhoyEZJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_size_of_model(model):\n",
        "    torch.save(model.state_dict(), \"temp.p\")\n",
        "    print('Size (MB):', os.path.getsize(\"temp.p\") / 1024**2)\n",
        "    os.remove('temp.p')"
      ],
      "metadata": {
        "id": "qiUzfqxzbH0s"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fill blanks in `quantize_model` function that performs quantization [1 point]"
      ],
      "metadata": {
        "id": "TUdeR8n7JHxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def quantize_model(model, qconfig_dict={}, input_shape=None):\n",
        "\n",
        "    print(f'QConfig \\n {qconfig_dict}')\n",
        "\n",
        "    # Layers with qconfig=None will not be quantized\n",
        "    model.qconfig = None\n",
        "\n",
        "    for mname, m in model.named_modules():\n",
        "      if mname in qconfig_dict.keys():\n",
        "        m.qconfig = qconfig_dict[mname]\n",
        "\n",
        "    print(f'\\n Model before preparation \\n{model}')\n",
        "\n",
        "    # Prepare the model for quantization by propagating qconfig\n",
        "    \n",
        "    torch.quantization.prepare(model, inplace=True)\n",
        "    \n",
        "    \n",
        "    print(f'\\n Model after preparation & before calibration (activation stats computation) \\n{model}')\n",
        "\n",
        "    # Collect statistics for quantization\n",
        "\n",
        "    for _ in range(20):\n",
        "        model(torch.randn(2, 3, 32, 32))\n",
        "    \n",
        "    print(f'\\n Model after calibration & before conversion \\n{model}')\n",
        "\n",
        "    torch.quantization.convert(model, inplace=True)\n",
        "\n",
        "    print(f'\\n Model after conversion \\n{model}')    \n",
        "    return model"
      ],
      "metadata": {
        "id": "m4hOcQDhF0ff"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import vgg16\n",
        "model = vgg16(pretrained=True)\n",
        "\n",
        "model.eval()\n",
        "for p in model.parameters():\n",
        "  p.requires_grad=False"
      ],
      "metadata": {
        "id": "7oDzFQt7LcJJ"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuyqsbfhULvY",
        "outputId": "bbdf4b07-db70-4896-d791-89db4b81599e"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fuse all possible layers [1 point]"
      ],
      "metadata": {
        "id": "f0Tn-IM3XEOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fmodel = copy.deepcopy(model)\n",
        "\n",
        "# Fuse all possible layers"
      ],
      "metadata": {
        "id": "iklQ2QlBOYiq"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f_modules_1 = [['0', '1'],\n",
        "                   ['2', '3'],\n",
        "                   ['5', '6'],\n",
        "                   ['7', '8'],\n",
        "                   ['10', '11'],\n",
        "                   ['12', '13'],\n",
        "                   ['14', '15'],\n",
        "                   ['17', '18'],\n",
        "                   ['19', '20'],\n",
        "                   ['21', '22'],\n",
        "                   ['24', '25'],\n",
        "                   ['26', '27'],\n",
        "                   ['28', '29']]"
      ],
      "metadata": {
        "id": "3_iYv28mL0Tk"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f_modules_2 = [['0', '1'], ['3', '4']]"
      ],
      "metadata": {
        "id": "rokqk3MnMZbf"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.quantization.fuse_modules(fmodel.features, f_modules_1, inplace=True)\n",
        "\n",
        "torch.quantization.fuse_modules(fmodel.classifier, f_modules_2, inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPuBZxDpIkKs",
        "outputId": "640e4353-60dc-42e7-d5bb-1c9412537b20"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): LinearReLU(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "  )\n",
              "  (1): Identity()\n",
              "  (2): Dropout(p=0.5, inplace=False)\n",
              "  (3): LinearReLU(\n",
              "    (0): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "  )\n",
              "  (4): Identity()\n",
              "  (5): Dropout(p=0.5, inplace=False)\n",
              "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quantize the whole model [1 point]\n",
        "\n",
        "\n",
        "1. whole model  using default PyTorch static quantization qconfig"
      ],
      "metadata": {
        "id": "C8MvxJEVQQ5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modify model to be quantizable and set qconfig_dict\n",
        "qmodel = copy.deepcopy(fmodel)\n",
        "qmodel = QuantWrapper(qmodel)\n",
        "qconfig_dict = {'': torch.quantization.get_default_qconfig('fbgemm')}"
      ],
      "metadata": {
        "id": "0XSEGpN2Ll3O"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qmodel = quantize_model(qmodel, qconfig_dict, input_shape=(1, 3, 224, 224))"
      ],
      "metadata": {
        "id": "63pLO90nINtY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de1835ba-0e11-4ea2-b94b-e4760f1dff9f"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QConfig \n",
            " {'': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})}\n",
            "\n",
            " Model before preparation \n",
            "QuantWrapper(\n",
            "  (quant): QuantStub()\n",
            "  (dequant): DeQuantStub()\n",
            "  (module): VGG(\n",
            "    (features): Sequential(\n",
            "      (0): ConvReLU2d(\n",
            "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (1): Identity()\n",
            "      (2): ConvReLU2d(\n",
            "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Identity()\n",
            "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (5): ConvReLU2d(\n",
            "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (6): Identity()\n",
            "      (7): ConvReLU2d(\n",
            "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (8): Identity()\n",
            "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (10): ConvReLU2d(\n",
            "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (11): Identity()\n",
            "      (12): ConvReLU2d(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (13): Identity()\n",
            "      (14): ConvReLU2d(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (15): Identity()\n",
            "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (17): ConvReLU2d(\n",
            "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (18): Identity()\n",
            "      (19): ConvReLU2d(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (20): Identity()\n",
            "      (21): ConvReLU2d(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (22): Identity()\n",
            "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (24): ConvReLU2d(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (25): Identity()\n",
            "      (26): ConvReLU2d(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (27): Identity()\n",
            "      (28): ConvReLU2d(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (29): Identity()\n",
            "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "    (classifier): Sequential(\n",
            "      (0): LinearReLU(\n",
            "        (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (1): Identity()\n",
            "      (2): Dropout(p=0.5, inplace=False)\n",
            "      (3): LinearReLU(\n",
            "        (0): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Identity()\n",
            "      (5): Dropout(p=0.5, inplace=False)\n",
            "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\n",
            " Model after preparation & before calibration (activation stats computation) \n",
            "QuantWrapper(\n",
            "  (quant): QuantStub(\n",
            "    (activation_post_process): HistogramObserver()\n",
            "  )\n",
            "  (dequant): DeQuantStub()\n",
            "  (module): VGG(\n",
            "    (features): Sequential(\n",
            "      (0): ConvReLU2d(\n",
            "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): HistogramObserver()\n",
            "      )\n",
            "      (1): Identity()\n",
            "      (2): ConvReLU2d(\n",
            "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): HistogramObserver()\n",
            "      )\n",
            "      (3): Identity()\n",
            "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (5): ConvReLU2d(\n",
            "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): HistogramObserver()\n",
            "      )\n",
            "      (6): Identity()\n",
            "      (7): ConvReLU2d(\n",
            "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): HistogramObserver()\n",
            "      )\n",
            "      (8): Identity()\n",
            "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (10): ConvReLU2d(\n",
            "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): HistogramObserver()\n",
            "      )\n",
            "      (11): Identity()\n",
            "      (12): ConvReLU2d(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): HistogramObserver()\n",
            "      )\n",
            "      (13): Identity()\n",
            "      (14): ConvReLU2d(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): HistogramObserver()\n",
            "      )\n",
            "      (15): Identity()\n",
            "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (17): ConvReLU2d(\n",
            "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): HistogramObserver()\n",
            "      )\n",
            "      (18): Identity()\n",
            "      (19): ConvReLU2d(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): HistogramObserver()\n",
            "      )\n",
            "      (20): Identity()\n",
            "      (21): ConvReLU2d(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): HistogramObserver()\n",
            "      )\n",
            "      (22): Identity()\n",
            "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (24): ConvReLU2d(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): HistogramObserver()\n",
            "      )\n",
            "      (25): Identity()\n",
            "      (26): ConvReLU2d(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): HistogramObserver()\n",
            "      )\n",
            "      (27): Identity()\n",
            "      (28): ConvReLU2d(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): HistogramObserver()\n",
            "      )\n",
            "      (29): Identity()\n",
            "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "    (classifier): Sequential(\n",
            "      (0): LinearReLU(\n",
            "        (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): HistogramObserver()\n",
            "      )\n",
            "      (1): Identity()\n",
            "      (2): Dropout(p=0.5, inplace=False)\n",
            "      (3): LinearReLU(\n",
            "        (0): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): HistogramObserver()\n",
            "      )\n",
            "      (4): Identity()\n",
            "      (5): Dropout(p=0.5, inplace=False)\n",
            "      (6): Linear(\n",
            "        in_features=4096, out_features=1000, bias=True\n",
            "        (activation_post_process): HistogramObserver()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/ao/quantization/observer.py:174: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  reduce_range will be deprecated in a future release of PyTorch.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Model after calibration & before conversion \n",
            "QuantWrapper(\n",
            "  (quant): QuantStub(\n",
            "    (activation_post_process): HistogramObserver()\n",
            "  )\n",
            "  (dequant): DeQuantStub()\n",
            "  (module): VGG(\n",
            "    (features): Sequential(\n",
            "      (0): ConvReLU2d(\n",
            "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): HistogramObserver()\n",
            "      )\n",
            "      (1): Identity()\n",
            "      (2): ConvReLU2d(\n",
            "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): HistogramObserver()\n",
            "      )\n",
            "      (3): Identity()\n",
            "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (5): ConvReLU2d(\n",
            "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): HistogramObserver()\n",
            "      )\n",
            "      (6): Identity()\n",
            "      (7): ConvReLU2d(\n",
            "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): HistogramObserver()\n",
            "      )\n",
            "      (8): Identity()\n",
            "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (10): ConvReLU2d(\n",
            "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): HistogramObserver()\n",
            "      )\n",
            "      (11): Identity()\n",
            "      (12): ConvReLU2d(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): HistogramObserver()\n",
            "      )\n",
            "      (13): Identity()\n",
            "      (14): ConvReLU2d(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): HistogramObserver()\n",
            "      )\n",
            "      (15): Identity()\n",
            "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (17): ConvReLU2d(\n",
            "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): HistogramObserver()\n",
            "      )\n",
            "      (18): Identity()\n",
            "      (19): ConvReLU2d(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): HistogramObserver()\n",
            "      )\n",
            "      (20): Identity()\n",
            "      (21): ConvReLU2d(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): HistogramObserver()\n",
            "      )\n",
            "      (22): Identity()\n",
            "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (24): ConvReLU2d(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): HistogramObserver()\n",
            "      )\n",
            "      (25): Identity()\n",
            "      (26): ConvReLU2d(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): HistogramObserver()\n",
            "      )\n",
            "      (27): Identity()\n",
            "      (28): ConvReLU2d(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): HistogramObserver()\n",
            "      )\n",
            "      (29): Identity()\n",
            "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "    (classifier): Sequential(\n",
            "      (0): LinearReLU(\n",
            "        (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): HistogramObserver()\n",
            "      )\n",
            "      (1): Identity()\n",
            "      (2): Dropout(p=0.5, inplace=False)\n",
            "      (3): LinearReLU(\n",
            "        (0): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): HistogramObserver()\n",
            "      )\n",
            "      (4): Identity()\n",
            "      (5): Dropout(p=0.5, inplace=False)\n",
            "      (6): Linear(\n",
            "        in_features=4096, out_features=1000, bias=True\n",
            "        (activation_post_process): HistogramObserver()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/ao/quantization/observer.py:886: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  src_bin_begin // dst_bin_width, 0, self.dst_nbins - 1\n",
            "/usr/local/lib/python3.7/dist-packages/torch/ao/quantization/observer.py:891: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  src_bin_end // dst_bin_width, 0, self.dst_nbins - 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Model after conversion \n",
            "QuantWrapper(\n",
            "  (quant): Quantize(scale=tensor([0.0683]), zero_point=tensor([62]), dtype=torch.quint8)\n",
            "  (dequant): DeQuantize()\n",
            "  (module): VGG(\n",
            "    (features): Sequential(\n",
            "      (0): QuantizedConvReLU2d(3, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.06496402621269226, zero_point=0, padding=(1, 1))\n",
            "      (1): Identity()\n",
            "      (2): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.16896606981754303, zero_point=0, padding=(1, 1))\n",
            "      (3): Identity()\n",
            "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (5): QuantizedConvReLU2d(64, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.24654534459114075, zero_point=0, padding=(1, 1))\n",
            "      (6): Identity()\n",
            "      (7): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.4477006196975708, zero_point=0, padding=(1, 1))\n",
            "      (8): Identity()\n",
            "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (10): QuantizedConvReLU2d(128, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.47004371881484985, zero_point=0, padding=(1, 1))\n",
            "      (11): Identity()\n",
            "      (12): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.5439562797546387, zero_point=0, padding=(1, 1))\n",
            "      (13): Identity()\n",
            "      (14): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.8162778615951538, zero_point=0, padding=(1, 1))\n",
            "      (15): Identity()\n",
            "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (17): QuantizedConvReLU2d(256, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.738710343837738, zero_point=0, padding=(1, 1))\n",
            "      (18): Identity()\n",
            "      (19): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.47262638807296753, zero_point=0, padding=(1, 1))\n",
            "      (20): Identity()\n",
            "      (21): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.2633339762687683, zero_point=0, padding=(1, 1))\n",
            "      (22): Identity()\n",
            "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (24): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.3156604468822479, zero_point=0, padding=(1, 1))\n",
            "      (25): Identity()\n",
            "      (26): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.16962966322898865, zero_point=0, padding=(1, 1))\n",
            "      (27): Identity()\n",
            "      (28): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.1029893085360527, zero_point=0, padding=(1, 1))\n",
            "      (29): Identity()\n",
            "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "    (classifier): Sequential(\n",
            "      (0): QuantizedLinearReLU(in_features=25088, out_features=4096, scale=0.17578691244125366, zero_point=0, qscheme=torch.per_channel_affine)\n",
            "      (1): Identity()\n",
            "      (2): Dropout(p=0.5, inplace=False)\n",
            "      (3): QuantizedLinearReLU(in_features=4096, out_features=4096, scale=0.10912235826253891, zero_point=0, qscheme=torch.per_channel_affine)\n",
            "      (4): Identity()\n",
            "      (5): Dropout(p=0.5, inplace=False)\n",
            "      (6): QuantizedLinear(in_features=4096, out_features=1000, scale=0.3030414283275604, zero_point=43, qscheme=torch.per_channel_affine)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_size_of_model(model)\n",
        "print_size_of_model(qmodel)"
      ],
      "metadata": {
        "id": "akrjUh3RSiS4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "962f00d8-f38a-45ed-8636-38814b60539c"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size (MB): 527.8018236160278\n",
            "Size (MB): 132.21978664398193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check inference time\n",
        "shape = (2, 3, 228, 224)\n",
        "x = torch.randn(shape)"
      ],
      "metadata": {
        "id": "FBr7uBFbMCe2"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit _ = model(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNidGzSeLfWj",
        "outputId": "6969663e-fd45-4848-fe27-8476e8ceb37e"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 1.02 s per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit _ = qmodel(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gr96qqLyMSIp",
        "outputId": "01422625-1ee1-457b-9b02-345bc896b1d1"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 628 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quantize a  part of the model [1 point]\n",
        "\n",
        "Namely\n",
        "  - all convolutional layers using Min-Max observers \n",
        "  - first fully-connected layer using default PyTorch static quantization qconfig "
      ],
      "metadata": {
        "id": "KTlLAXvD1wD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fc_list = ['classifier.0']"
      ],
      "metadata": {
        "id": "DuB8vdj_OIoY"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qmodel = copy.deepcopy(fmodel)\n",
        "\n",
        "# Modify model to be quantizable and set qconfig_dict\n",
        "qmodel.features = QuantWrapper(qmodel.features)\n",
        "qmodel.classifier[0] = QuantWrapper(qmodel.classifier[0])\n",
        "qconfig_dict = {}"
      ],
      "metadata": {
        "id": "pQ2hTuFRXWo_"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for conv, _ in qmodel.named_modules():\n",
        "    \n",
        "    if 'features' in conv:\n",
        "        qconfig_dict[conv] = torch.quantization.default_qconfig\n",
        "\n",
        "qconfig_dict[fc_list[0]] = torch.quantization.get_default_qconfig('fbgemm')"
      ],
      "metadata": {
        "id": "6HV6YgVJOTX_"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quantize the model\n",
        "qmodel = quantize_model(qmodel, qconfig_dict, input_shape=(1, 3, 224, 224))"
      ],
      "metadata": {
        "id": "A60GfXzYapPi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efcffd34-eeef-46b6-c3b0-e44c37650552"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QConfig \n",
            " {'features': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.quant': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.dequant': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.0': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.0.0': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.0.1': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.1': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.2': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.2.0': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.2.1': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.3': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.4': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.5': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.5.0': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.5.1': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.6': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.7': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.7.0': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.7.1': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.8': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.9': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.10': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.10.0': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.10.1': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.11': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.12': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.12.0': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.12.1': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.13': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.14': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.14.0': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.14.1': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.15': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.16': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.17': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.17.0': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.17.1': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.18': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.19': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.19.0': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.19.1': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.20': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.21': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.21.0': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.21.1': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.22': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.23': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.24': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.24.0': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.24.1': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.25': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.26': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.26.0': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.26.1': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.27': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.28': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.28.0': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.28.1': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.29': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'features.module.30': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){}), 'classifier.0': QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})}\n",
            "\n",
            " Model before preparation \n",
            "VGG(\n",
            "  (features): QuantWrapper(\n",
            "    (quant): QuantStub()\n",
            "    (dequant): DeQuantStub()\n",
            "    (module): Sequential(\n",
            "      (0): ConvReLU2d(\n",
            "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (1): Identity()\n",
            "      (2): ConvReLU2d(\n",
            "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Identity()\n",
            "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (5): ConvReLU2d(\n",
            "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (6): Identity()\n",
            "      (7): ConvReLU2d(\n",
            "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (8): Identity()\n",
            "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (10): ConvReLU2d(\n",
            "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (11): Identity()\n",
            "      (12): ConvReLU2d(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (13): Identity()\n",
            "      (14): ConvReLU2d(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (15): Identity()\n",
            "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (17): ConvReLU2d(\n",
            "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (18): Identity()\n",
            "      (19): ConvReLU2d(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (20): Identity()\n",
            "      (21): ConvReLU2d(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (22): Identity()\n",
            "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (24): ConvReLU2d(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (25): Identity()\n",
            "      (26): ConvReLU2d(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (27): Identity()\n",
            "      (28): ConvReLU2d(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (29): Identity()\n",
            "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): QuantWrapper(\n",
            "      (quant): QuantStub()\n",
            "      (dequant): DeQuantStub()\n",
            "      (module): LinearReLU(\n",
            "        (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Identity()\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): LinearReLU(\n",
            "      (0): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "      (1): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Identity()\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            " Model after preparation & before calibration (activation stats computation) \n",
            "VGG(\n",
            "  (features): QuantWrapper(\n",
            "    (quant): QuantStub(\n",
            "      (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
            "    )\n",
            "    (dequant): DeQuantStub()\n",
            "    (module): Sequential(\n",
            "      (0): ConvReLU2d(\n",
            "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
            "      )\n",
            "      (1): Identity()\n",
            "      (2): ConvReLU2d(\n",
            "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
            "      )\n",
            "      (3): Identity()\n",
            "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (5): ConvReLU2d(\n",
            "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
            "      )\n",
            "      (6): Identity()\n",
            "      (7): ConvReLU2d(\n",
            "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
            "      )\n",
            "      (8): Identity()\n",
            "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (10): ConvReLU2d(\n",
            "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
            "      )\n",
            "      (11): Identity()\n",
            "      (12): ConvReLU2d(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
            "      )\n",
            "      (13): Identity()\n",
            "      (14): ConvReLU2d(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
            "      )\n",
            "      (15): Identity()\n",
            "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (17): ConvReLU2d(\n",
            "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
            "      )\n",
            "      (18): Identity()\n",
            "      (19): ConvReLU2d(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
            "      )\n",
            "      (20): Identity()\n",
            "      (21): ConvReLU2d(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
            "      )\n",
            "      (22): Identity()\n",
            "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (24): ConvReLU2d(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
            "      )\n",
            "      (25): Identity()\n",
            "      (26): ConvReLU2d(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
            "      )\n",
            "      (27): Identity()\n",
            "      (28): ConvReLU2d(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
            "      )\n",
            "      (29): Identity()\n",
            "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): QuantWrapper(\n",
            "      (quant): QuantStub(\n",
            "        (activation_post_process): HistogramObserver()\n",
            "      )\n",
            "      (dequant): DeQuantStub()\n",
            "      (module): LinearReLU(\n",
            "        (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): HistogramObserver()\n",
            "      )\n",
            "    )\n",
            "    (1): Identity()\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): LinearReLU(\n",
            "      (0): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "      (1): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Identity()\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/ao/quantization/observer.py:174: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  reduce_range will be deprecated in a future release of PyTorch.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Model after calibration & before conversion \n",
            "VGG(\n",
            "  (features): QuantWrapper(\n",
            "    (quant): QuantStub(\n",
            "      (activation_post_process): MinMaxObserver(min_val=-4.225592136383057, max_val=5.281889915466309)\n",
            "    )\n",
            "    (dequant): DeQuantStub()\n",
            "    (module): Sequential(\n",
            "      (0): ConvReLU2d(\n",
            "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): MinMaxObserver(min_val=0.0, max_val=11.145073890686035)\n",
            "      )\n",
            "      (1): Identity()\n",
            "      (2): ConvReLU2d(\n",
            "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): MinMaxObserver(min_val=0.0, max_val=30.809837341308594)\n",
            "      )\n",
            "      (3): Identity()\n",
            "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (5): ConvReLU2d(\n",
            "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): MinMaxObserver(min_val=0.0, max_val=40.9269905090332)\n",
            "      )\n",
            "      (6): Identity()\n",
            "      (7): ConvReLU2d(\n",
            "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): MinMaxObserver(min_val=0.0, max_val=69.62272644042969)\n",
            "      )\n",
            "      (8): Identity()\n",
            "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (10): ConvReLU2d(\n",
            "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): MinMaxObserver(min_val=0.0, max_val=78.58544921875)\n",
            "      )\n",
            "      (11): Identity()\n",
            "      (12): ConvReLU2d(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): MinMaxObserver(min_val=0.0, max_val=80.13418579101562)\n",
            "      )\n",
            "      (13): Identity()\n",
            "      (14): ConvReLU2d(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): MinMaxObserver(min_val=0.0, max_val=122.70362854003906)\n",
            "      )\n",
            "      (15): Identity()\n",
            "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (17): ConvReLU2d(\n",
            "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): MinMaxObserver(min_val=0.0, max_val=104.8681869506836)\n",
            "      )\n",
            "      (18): Identity()\n",
            "      (19): ConvReLU2d(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): MinMaxObserver(min_val=0.0, max_val=73.04352569580078)\n",
            "      )\n",
            "      (20): Identity()\n",
            "      (21): ConvReLU2d(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): MinMaxObserver(min_val=0.0, max_val=40.572269439697266)\n",
            "      )\n",
            "      (22): Identity()\n",
            "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (24): ConvReLU2d(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): MinMaxObserver(min_val=0.0, max_val=42.42301940917969)\n",
            "      )\n",
            "      (25): Identity()\n",
            "      (26): ConvReLU2d(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): MinMaxObserver(min_val=0.0, max_val=23.223052978515625)\n",
            "      )\n",
            "      (27): Identity()\n",
            "      (28): ConvReLU2d(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): MinMaxObserver(min_val=0.0, max_val=17.009672164916992)\n",
            "      )\n",
            "      (29): Identity()\n",
            "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): QuantWrapper(\n",
            "      (quant): QuantStub(\n",
            "        (activation_post_process): HistogramObserver()\n",
            "      )\n",
            "      (dequant): DeQuantStub()\n",
            "      (module): LinearReLU(\n",
            "        (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "        (1): ReLU(inplace=True)\n",
            "        (activation_post_process): HistogramObserver()\n",
            "      )\n",
            "    )\n",
            "    (1): Identity()\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): LinearReLU(\n",
            "      (0): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "      (1): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Identity()\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/ao/quantization/observer.py:886: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  src_bin_begin // dst_bin_width, 0, self.dst_nbins - 1\n",
            "/usr/local/lib/python3.7/dist-packages/torch/ao/quantization/observer.py:891: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  src_bin_end // dst_bin_width, 0, self.dst_nbins - 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Model after conversion \n",
            "VGG(\n",
            "  (features): QuantWrapper(\n",
            "    (quant): Quantize(scale=tensor([0.0749]), zero_point=tensor([56]), dtype=torch.quint8)\n",
            "    (dequant): DeQuantize()\n",
            "    (module): Sequential(\n",
            "      (0): QuantizedConvReLU2d(3, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.08775648474693298, zero_point=0, padding=(1, 1))\n",
            "      (1): Identity()\n",
            "      (2): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.24259714782238007, zero_point=0, padding=(1, 1))\n",
            "      (3): Identity()\n",
            "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (5): QuantizedConvReLU2d(64, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.3222597539424896, zero_point=0, padding=(1, 1))\n",
            "      (6): Identity()\n",
            "      (7): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.5482104420661926, zero_point=0, padding=(1, 1))\n",
            "      (8): Identity()\n",
            "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (10): QuantizedConvReLU2d(128, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.6187830567359924, zero_point=0, padding=(1, 1))\n",
            "      (11): Identity()\n",
            "      (12): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.6309778690338135, zero_point=0, padding=(1, 1))\n",
            "      (13): Identity()\n",
            "      (14): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.9661703109741211, zero_point=0, padding=(1, 1))\n",
            "      (15): Identity()\n",
            "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (17): QuantizedConvReLU2d(256, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.8257337808609009, zero_point=0, padding=(1, 1))\n",
            "      (18): Identity()\n",
            "      (19): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.5751459002494812, zero_point=0, padding=(1, 1))\n",
            "      (20): Identity()\n",
            "      (21): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.3194666802883148, zero_point=0, padding=(1, 1))\n",
            "      (22): Identity()\n",
            "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (24): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.33403950929641724, zero_point=0, padding=(1, 1))\n",
            "      (25): Identity()\n",
            "      (26): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.1828586906194687, zero_point=0, padding=(1, 1))\n",
            "      (27): Identity()\n",
            "      (28): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.13393442332744598, zero_point=0, padding=(1, 1))\n",
            "      (29): Identity()\n",
            "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): QuantWrapper(\n",
            "      (quant): Quantize(scale=tensor([0.1041]), zero_point=tensor([0]), dtype=torch.quint8)\n",
            "      (dequant): DeQuantize()\n",
            "      (module): QuantizedLinearReLU(in_features=25088, out_features=4096, scale=0.18802018463611603, zero_point=0, qscheme=torch.per_channel_affine)\n",
            "    )\n",
            "    (1): Identity()\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): LinearReLU(\n",
            "      (0): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "      (1): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Identity()\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_size_of_model(model)\n",
        "print_size_of_model(qmodel)"
      ],
      "metadata": {
        "id": "clDPw2_fKTac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fbf81a4-cca4-4ee4-80ae-c031615a63f7"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size (MB): 527.8018236160278\n",
            "Size (MB): 191.7883596420288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check inference time\n",
        "shape = (2, 3, 228, 224)\n",
        "x = torch.randn(shape)"
      ],
      "metadata": {
        "id": "9stt7IZ5bMi8"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit _ = model(x)"
      ],
      "metadata": {
        "id": "nhrKGjKsbRMu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d79d375-48c1-4bbc-c965-e34aaf8b30da"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 1.02 s per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit _ = qmodel(x)"
      ],
      "metadata": {
        "id": "XFC1cBE6bRhw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0879522-dc7f-48c8-bb22-bd37187e12a7"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 627 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "80Ss0QV9OynF"
      },
      "execution_count": 200,
      "outputs": []
    }
  ]
}